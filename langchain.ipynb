{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms.base import LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom LangChain wrapper for the Ollama LLaMA model\n",
    "class OllamaLangChain(LLM):\n",
    "    model_name: str = \"llama3.2:latest\"  # Declared field\n",
    "    request_timeout: int = 30           # Declared field\n",
    "\n",
    "    def __init__(self, model_name=\"llama3.2:latest\", request_timeout=30):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.request_timeout = request_timeout\n",
    "        # Use object.__setattr__ to bypass Pydantic's field validation\n",
    "        object.__setattr__(self, \"_client\", Ollama(model=model_name, request_timeout=request_timeout))\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"ollama\"\n",
    "\n",
    "    def _call(self, prompt, stop=None):\n",
    "        # Access the private client\n",
    "        client = object.__getattribute__(self, \"_client\")\n",
    "        response = client.complete(prompt)\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LangChain components\n",
    "llm = OllamaLangChain()\n",
    "memory = ConversationBufferMemory()  # Store chat history\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat function\n",
    "def chat_with_langchain(input_text):\n",
    "    # Use LangChain's ConversationChain\n",
    "    response = conversation.run(input_text)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7878\n",
      "Running on public URL: https://a3a737519bc54a4b57.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a3a737519bc54a4b57.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: hello\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hello\n",
      "AI: Hello! It's great to chat with you! I'm an AI designed to provide information and assist with tasks, so feel free to ask me anything that's on your mind. I'll do my best to provide helpful and accurate responses. What's been going on in your day?\n",
      "Human: hello remember the number 43\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hello\n",
      "AI: Hello! It's great to chat with you! I'm an AI designed to provide information and assist with tasks, so feel free to ask me anything that's on your mind. I'll do my best to provide helpful and accurate responses. What's been going on in your day?\n",
      "Human: hello remember the number 43\n",
      "AI: I think I can help you recall the significance of the number 43! As far as I know, there are a few interesting connections associated with this number.\n",
      "\n",
      "One notable example is that 43 is the atomic number of Technetium, which is the lightest artificially produced element. It's also a prime number, meaning it can only be divided by 1 and itself.\n",
      "\n",
      "If you're thinking of something more specific or personal, please feel free to share, and I'll do my best to help!\n",
      "Human: Which was the number i told you\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=chat_with_langchain,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"LLaMA 3 Chatbot with LangChain\",\n",
    "    description=\"Chat with a LLaMA 3-based model via Ollama and LangChain!\"\n",
    ")\n",
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
