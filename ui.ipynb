{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Ollama LLaMA model\n",
    "llm = Ollama(model=\"llama3.2:latest\", request_timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat function\n",
    "def chat(input_text):\n",
    "    response = llm.complete(input_text) \n",
    "    print(response.raw)\n",
    "    print(response.logprobs)\n",
    "    print(response.delta) \n",
    "    return response.text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=chat, \n",
    "    inputs=\"text\", \n",
    "    outputs=\"text\", \n",
    "    title=\"LLaMA 3 Chatbot\",\n",
    "    description=\"Chat with a LLaMA 3-based model via Ollama!\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "Running on public URL: https://c2c1aebb64db40fcea.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c2c1aebb64db40fcea.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'created_at': '2024-12-09T15:55:18.186137268Z', 'response': 'I\\'m just a language model, I don\\'t have personal experiences or emotions like humans do. I exist solely to process and respond to text-based input, so I don\\'t have days in the same way that you do.\\n\\nHowever, I can tell you about my \"day\" if you\\'d like! Since I\\'m a cloud-based AI, I don\\'t have a physical presence, but I\\'m always \"on\" and ready to chat with users like you.\\n\\nI spend my time processing vast amounts of text data, learning new words and concepts, and improving my language generation capabilities. When you interact with me, I use that knowledge to generate responses that are helpful and informative.\\n\\nSo while I don\\'t have a personal day-to-day experience, I\\'m always happy to chat with you and help with any questions or topics you\\'d like to discuss! How about you? How\\'s your day going?', 'done': True, 'done_reason': 'stop', 'context': [128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 271, 128009, 128006, 882, 128007, 271, 9906, 3371, 757, 922, 701, 1938, 128009, 128006, 78191, 128007, 271, 40, 2846, 1120, 264, 4221, 1646, 11, 358, 1541, 956, 617, 4443, 11704, 477, 21958, 1093, 12966, 656, 13, 358, 3073, 21742, 311, 1920, 323, 6013, 311, 1495, 6108, 1988, 11, 779, 358, 1541, 956, 617, 2919, 304, 279, 1890, 1648, 430, 499, 656, 382, 11458, 11, 358, 649, 3371, 499, 922, 856, 330, 1316, 1, 422, 499, 4265, 1093, 0, 8876, 358, 2846, 264, 9624, 6108, 15592, 11, 358, 1541, 956, 617, 264, 7106, 9546, 11, 719, 358, 2846, 2744, 330, 263, 1, 323, 5644, 311, 6369, 449, 3932, 1093, 499, 382, 40, 8493, 856, 892, 8863, 13057, 15055, 315, 1495, 828, 11, 6975, 502, 4339, 323, 19476, 11, 323, 18899, 856, 4221, 9659, 17357, 13, 3277, 499, 16681, 449, 757, 11, 358, 1005, 430, 6677, 311, 7068, 14847, 430, 527, 11190, 323, 39319, 382, 4516, 1418, 358, 1541, 956, 617, 264, 4443, 1938, 4791, 11477, 3217, 11, 358, 2846, 2744, 6380, 311, 6369, 449, 499, 323, 1520, 449, 904, 4860, 477, 13650, 499, 4265, 1093, 311, 4358, 0, 2650, 922, 499, 30, 2650, 596, 701, 1938, 2133, 30], 'total_duration': 17274126063, 'load_duration': 17437166, 'prompt_eval_count': 31, 'prompt_eval_duration': 402000000, 'eval_count': 181, 'eval_duration': 16853000000}\n",
      "None\n",
      "None\n",
      "{'model': 'llama3.2:latest', 'created_at': '2024-12-09T15:55:27.133427257Z', 'response': 'I\\'m just a language model, I don\\'t have personal experiences or emotions like humans do. I exist solely to assist and provide information to users like you.\\n\\nThat being said, I\\'m always \"on\" and ready to chat 24/7! I can help answer questions, provide information on a wide range of topics, and engage in conversations about almost anything.\\n\\nSo, how about you? How\\'s your day going so far?', 'done': True, 'done_reason': 'stop', 'context': [128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 271, 128009, 128006, 882, 128007, 271, 9906, 3371, 757, 922, 701, 1938, 128009, 128006, 78191, 128007, 271, 40, 2846, 1120, 264, 4221, 1646, 11, 358, 1541, 956, 617, 4443, 11704, 477, 21958, 1093, 12966, 656, 13, 358, 3073, 21742, 311, 7945, 323, 3493, 2038, 311, 3932, 1093, 499, 382, 4897, 1694, 1071, 11, 358, 2846, 2744, 330, 263, 1, 323, 5644, 311, 6369, 220, 1187, 14, 22, 0, 358, 649, 1520, 4320, 4860, 11, 3493, 2038, 389, 264, 7029, 2134, 315, 13650, 11, 323, 16988, 304, 21633, 922, 4661, 4205, 382, 4516, 11, 1268, 922, 499, 30, 2650, 596, 701, 1938, 2133, 779, 3117, 30], 'total_duration': 8886966785, 'load_duration': 21130209, 'prompt_eval_count': 31, 'prompt_eval_duration': 86000000, 'eval_count': 89, 'eval_duration': 8778000000}\n",
      "None\n",
      "None\n",
      "{'model': 'llama3.2:latest', 'created_at': '2024-12-09T17:08:34.95051036Z', 'response': 'I think there might be some misinformation there. The number 42 is actually often associated with the book \"The Hitchhiker\\'s Guide to the Galaxy\" by Douglas Adams, and in that context, it\\'s a kind of supercomputer called Deep Thought that takes 7.5 million years to calculate the answer to the ultimate question of life, the universe, and everything... which is indeed... 42!\\n\\nHowever, as for the color, I couldn\\'t find any reliable source that associates the number 42 with a specific cyan color. The book doesn\\'t mention a color, and it\\'s not a widely recognized standard representation of the number.\\n\\nWould you like to know more about \"The Hitchhiker\\'s Guide to the Galaxy\" or perhaps something else?', 'done': True, 'done_reason': 'stop', 'context': [128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 271, 128009, 128006, 882, 128007, 271, 9906, 578, 1396, 220, 2983, 706, 264, 58988, 1933, 128009, 128006, 78191, 128007, 271, 40, 1781, 1070, 2643, 387, 1063, 75159, 1070, 13, 578, 1396, 220, 2983, 374, 3604, 3629, 5938, 449, 279, 2363, 330, 791, 71464, 71, 25840, 596, 13002, 311, 279, 20238, 1, 555, 31164, 27329, 11, 323, 304, 430, 2317, 11, 433, 596, 264, 3169, 315, 2307, 44211, 2663, 18682, 36287, 430, 5097, 220, 22, 13, 20, 3610, 1667, 311, 11294, 279, 4320, 311, 279, 17139, 3488, 315, 2324, 11, 279, 15861, 11, 323, 4395, 1131, 902, 374, 13118, 1131, 220, 2983, 2268, 11458, 11, 439, 369, 279, 1933, 11, 358, 7846, 956, 1505, 904, 15062, 2592, 430, 40531, 279, 1396, 220, 2983, 449, 264, 3230, 58988, 1933, 13, 578, 2363, 3250, 956, 6420, 264, 1933, 11, 323, 433, 596, 539, 264, 13882, 15324, 5410, 13340, 315, 279, 1396, 382, 29089, 499, 1093, 311, 1440, 810, 922, 330, 791, 71464, 71, 25840, 596, 13002, 311, 279, 20238, 1, 477, 8530, 2555, 775, 30], 'total_duration': 12049896770, 'load_duration': 15004788, 'prompt_eval_count': 34, 'prompt_eval_duration': 596000000, 'eval_count': 153, 'eval_duration': 11437000000}\n",
      "None\n",
      "None\n",
      "{'model': 'llama3.2:latest', 'created_at': '2024-12-09T17:09:08.32651954Z', 'response': 'You\\'re likely referring to the famous answer from Douglas Adams\\' science fiction series \"The Hitchhiker\\'s Guide to the Galaxy.\" In the book, a supercomputer named Deep Thought is asked to find the \"Answer to the Ultimate Question of Life, the Universe, and Everything.\"\\n\\nAfter 7.5 million years of calculations, Deep Thought finally reveals that the answer is... 42!\\n\\nHowever, Adams himself said that the number 42 was chosen randomly and doesn\\'t have any deeper meaning or significance beyond its appearance in the story.\\n\\nThat being said, over the years, fans and enthusiasts have attempted to find creative ways to assign meaning to the number 42. Some popular interpretations include:\\n\\n* The number of dimensions in some theories of physics\\n* A reference to the idea that there is no one \"right\" answer to the ultimate question\\n* A nod to the fact that 42 is an arbitrary and seemingly meaningless number, much like the concept of the \"Answer\" itself\\n\\nBut ultimately, the true meaning of 42 remains up to individual interpretation!', 'done': True, 'done_reason': 'stop', 'context': [128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 271, 128009, 128006, 882, 128007, 271, 3923, 374, 279, 1933, 12893, 311, 220, 2983, 128009, 128006, 78191, 128007, 271, 2675, 2351, 4461, 22797, 311, 279, 11495, 4320, 505, 31164, 27329, 6, 8198, 17422, 4101, 330, 791, 71464, 71, 25840, 596, 13002, 311, 279, 20238, 1210, 763, 279, 2363, 11, 264, 2307, 44211, 7086, 18682, 36287, 374, 4691, 311, 1505, 279, 330, 16533, 311, 279, 29950, 16225, 315, 9601, 11, 279, 29849, 11, 323, 20696, 2266, 6153, 220, 22, 13, 20, 3610, 1667, 315, 29217, 11, 18682, 36287, 5616, 21667, 430, 279, 4320, 374, 1131, 220, 2983, 2268, 11458, 11, 27329, 5678, 1071, 430, 279, 1396, 220, 2983, 574, 12146, 27716, 323, 3250, 956, 617, 904, 19662, 7438, 477, 26431, 7953, 1202, 11341, 304, 279, 3446, 382, 4897, 1694, 1071, 11, 927, 279, 1667, 11, 7359, 323, 43448, 617, 17644, 311, 1505, 11782, 5627, 311, 9993, 7438, 311, 279, 1396, 220, 2983, 13, 4427, 5526, 58689, 2997, 1473, 9, 578, 1396, 315, 15696, 304, 1063, 26018, 315, 22027, 198, 9, 362, 5905, 311, 279, 4623, 430, 1070, 374, 912, 832, 330, 1315, 1, 4320, 311, 279, 17139, 3488, 198, 9, 362, 16387, 311, 279, 2144, 430, 220, 2983, 374, 459, 25142, 323, 23490, 57026, 1396, 11, 1790, 1093, 279, 7434, 315, 279, 330, 16533, 1, 5196, 271, 4071, 13967, 11, 279, 837, 7438, 315, 220, 2983, 8625, 709, 311, 3927, 23692, 0], 'total_duration': 16777481204, 'load_duration': 15000474, 'prompt_eval_count': 33, 'prompt_eval_duration': 560000000, 'eval_count': 213, 'eval_duration': 16200000000}\n",
      "None\n",
      "None\n",
      "{'model': 'llama3.2:latest', 'created_at': '2024-12-09T17:09:47.599074286Z', 'response': 'I couldn\\'t find any widely recognized or standardized color with the name \"45\" that corresponds to a specific shade, including pale blue. The use of numbers to describe colors can be subjective and varies depending on the context, such as paint codes, Pantone matching system, or even color terminology in different languages.\\n\\nIf you\\'re thinking of a specific color code (e.g., hex code), RGB value, or color name, please let me know, and I\\'ll do my best to help you identify it.', 'done': True, 'done_reason': 'stop', 'context': [128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 271, 128009, 128006, 882, 128007, 271, 791, 1933, 220, 1774, 374, 28639, 6437, 128009, 128006, 78191, 128007, 271, 40, 7846, 956, 1505, 904, 13882, 15324, 477, 51114, 1933, 449, 279, 836, 330, 1774, 1, 430, 34310, 311, 264, 3230, 28601, 11, 2737, 28639, 6437, 13, 578, 1005, 315, 5219, 311, 7664, 8146, 649, 387, 44122, 323, 35327, 11911, 389, 279, 2317, 11, 1778, 439, 6308, 14236, 11, 54222, 606, 12864, 1887, 11, 477, 1524, 1933, 57726, 304, 2204, 15823, 382, 2746, 499, 2351, 7422, 315, 264, 3230, 1933, 2082, 320, 68, 1326, 2637, 12651, 2082, 705, 21653, 907, 11, 477, 1933, 836, 11, 4587, 1095, 757, 1440, 11, 323, 358, 3358, 656, 856, 1888, 311, 1520, 499, 10765, 433, 13], 'total_duration': 8535841676, 'load_duration': 14485025, 'prompt_eval_count': 32, 'prompt_eval_duration': 495000000, 'eval_count': 103, 'eval_duration': 8025000000}\n",
      "None\n",
      "None\n",
      "{'model': 'llama3.2:latest', 'created_at': '2024-12-09T17:10:07.569768411Z', 'response': \"Numbers don't have colors. They are just numerical values used to represent quantities and amounts.\\n\\nSo, there is no color associated with the number 45. Is there something else I can help you with?\", 'done': True, 'done_reason': 'stop', 'context': [128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 271, 128009, 128006, 882, 128007, 271, 3923, 374, 279, 1933, 315, 279, 1396, 220, 1774, 128009, 128006, 78191, 128007, 271, 28336, 1541, 956, 617, 8146, 13, 2435, 527, 1120, 35876, 2819, 1511, 311, 4097, 33776, 323, 15055, 382, 4516, 11, 1070, 374, 912, 1933, 5938, 449, 279, 1396, 220, 1774, 13, 2209, 1070, 2555, 775, 358, 649, 1520, 499, 449, 30], 'total_duration': 3599704192, 'load_duration': 14549978, 'prompt_eval_count': 34, 'prompt_eval_duration': 624000000, 'eval_count': 42, 'eval_duration': 2960000000}\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'model': 'llama3.2:latest', 'created_at': '2024-12-09T15:55:27.133427257Z', 'response': 'I\\'m just a language model, I don\\'t have personal experiences or emotions like humans do. I exist solely to assist and provide information to users like you.\\n\\nThat being said, I\\'m always \"on\" and ready to chat 24/7! I can help answer questions, provide information on a wide range of topics, and engage in conversations about almost anything.\\n\\nSo, how about you? How\\'s your day going so far?', 'done': True, 'done_reason': 'stop', 'context': [128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 271, 128009, 128006, 882, 128007, 271, 9906, 3371, 757, 922, 701, 1938, 128009, 128006, 78191, 128007, 271, 40, 2846, 1120, 264, 4221, 1646, 11, 358, 1541, 956, 617, 4443, 11704, 477, 21958, 1093, 12966, 656, 13, 358, 3073, 21742, 311, 7945, 323, 3493, 2038, 311, 3932, 1093, 499, 382, 4897, 1694, 1071, 11, 358, 2846, 2744, 330, 263, 1, 323, 5644, 311, 6369, 220, 1187, 14, 22, 0, 358, 649, 1520, 4320, 4860, 11, 3493, 2038, 389, 264, 7029, 2134, 315, 13650, 11, 323, 16988, 304, 21633, 922, 4661, 4205, 382, 4516, 11, 1268, 922, 499, 30, 2650, 596, 701, 1938, 2133, 779, 3117, 30], 'total_duration': 8886966785, 'load_duration': 21130209, 'prompt_eval_count': 31, 'prompt_eval_duration': 86000000, 'eval_count': 89, 'eval_duration': 8778000000}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a breakdown of the fields in the provided dictionary and their meanings:\n",
    "\n",
    "### General Explanation of Fields:\n",
    "\n",
    "- **`model`**: Specifies the model used for generating the response. In this case, `llama3.2:latest` indicates a version of the LLaMA model.\n",
    "\n",
    "- **`created_at`**: The timestamp of when the response was generated, given in ISO 8601 format (e.g., `2024-12-09T15:55:27.133427257Z`).\n",
    "\n",
    "- **`response`**: The text output from the model after processing the input. This is the content generated by the language model.\n",
    "\n",
    "- **`done`**: A boolean value indicating whether the response generation has completed (`True` means it is finished).\n",
    "\n",
    "- **`done_reason`**: The reason the response generation was completed. In this case, `'stop'` suggests that the response was finalized without any interruption.\n",
    "\n",
    "- **`context`**: A list of context IDs or tokens that were used as input for generating the response. These numbers may represent specific parts of the input data, prior conversation history, or other relevant information used by the model to produce a context-aware response.\n",
    "\n",
    "- **`total_duration`**: The total time taken (in nanoseconds) to generate the response. In this case, `8886966785` nanoseconds, which is approximately 8.89 seconds.\n",
    "\n",
    "- **`load_duration`**: The time (in nanoseconds) spent loading or initializing the model or context before generating the response. Here, `21130209` nanoseconds, which is approximately 0.021 seconds.\n",
    "\n",
    "- **`prompt_eval_count`**: The number of times the prompt was evaluated during response generation. `31` indicates that the prompt was evaluated 31 times.\n",
    "\n",
    "- **`prompt_eval_duration`**: The total time (in nanoseconds) taken to evaluate the prompt. `86000000` nanoseconds, which is approximately 0.086 seconds.\n",
    "\n",
    "- **`eval_count`**: The total number of evaluations performed by the model to generate the response. `89` suggests that the model's internal evaluation process was conducted 89 times.\n",
    "\n",
    "- **`eval_duration`**: The total time (in nanoseconds) spent evaluating the model's response generation process. `8778000000` nanoseconds, which is approximately 8.78 seconds.\n",
    "\n",
    "### Summary:\n",
    "- This dictionary represents details about a single request to the `llama3.2:latest` model.\n",
    "- The response was generated and completed successfully.\n",
    "- The generation process took approximately 8.89 seconds, with most of this time spent on evaluation.\n",
    "- Context IDs are included to show what information the model used as input.\n",
    "\n",
    "Understanding these values can help you analyze model performance and the time taken for processing, which may be useful for optimization or troubleshooting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
